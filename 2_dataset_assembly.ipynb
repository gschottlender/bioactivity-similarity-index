{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1829abf5-1b0f-41a9-a8bf-512135231f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import random\n",
    "\n",
    "from src.ligand_clustering_functions import bemis_murcko_clustering, butina_clustering, compound_k_means_clustering, get_decoys, compute_tanimoto\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786af9c1-0d69-4a3e-b544-99a4364a57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_ligands(compound_list,fps,scaffolds,bm_clustering=True,butina_threshold=0.4,k_means_representatives=100):\n",
    "    \"\"\"Apply sequential clustering steps to a compound dataset in order to reduce redundancy and maximize structural diversity.\"\"\" \n",
    "    if bm_clustering == True:\n",
    "        # Apply Bemis-Murcko clustering\n",
    "        compound_list = bemis_murcko_clustering(compound_list,scaffolds)\n",
    "    if butina_threshold <1:    \n",
    "        # Apply Butina clustering. Set threshold == 1 to disable clustering.\n",
    "        compound_list = butina_clustering(compound_list,fps,threshold=butina_threshold)\n",
    "    if k_means_representatives:\n",
    "        # Apply a last k-means clustering for a final maximum number of compounds.\n",
    "        if len(compound_list) > k_means_representatives:\n",
    "            compound_list = compound_k_means_clustering(compound_list,fps,n_clusters=100)\n",
    "    return compound_list\n",
    "\n",
    "def generate_compound_pairs(\n",
    "    prot_list, \n",
    "    base_dataset, \n",
    "    fps, \n",
    "    scaffolds, \n",
    "    decoys, \n",
    "    n_decoys_per_lig=25, \n",
    "    decoys_proportion=2, \n",
    "    min_positives=25, \n",
    "    k_means_representatives=100, \n",
    "    butina_threshold=0.4,\n",
    "    tanimoto_threshold=0.4,\n",
    "    random_seed=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate compound pairs (S and N) for a list of proteins, using clustering and decoys.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prot_list : list\n",
    "        List of protein identifiers to process.\n",
    "    base_dataset : pd.DataFrame\n",
    "        Dataset with columns: 'lig', 'prot', 'activity', etc.\n",
    "    fps : dict or list\n",
    "        Fingerprints for the ligands.\n",
    "    scaffolds : dict or list\n",
    "        Scaffold assignments for the ligands.\n",
    "    decoys : dict or list\n",
    "        Decoys assigned for each active ligand.\n",
    "    n_decoys_per_lig : int, optional\n",
    "        Number of decoys to find per active ligand (default: 25).\n",
    "    decoys_proportion : float, optional\n",
    "        Proportion of decoys to sample relative to the number of actives (default: 2).\n",
    "    min_positives : int, optional\n",
    "        Minimum number of active ligands required to process a protein (default: 25).\n",
    "    k_means_representatives : int, optional\n",
    "        Number of representatives for K-means clustering (default: 100).\n",
    "    butina_threshold : float, optional\n",
    "        Similarity threshold for Butina clustering (default: 0.4).\n",
    "    tanimoto_threshold: float, optional\n",
    "        Maximum Tanimoto similarity of compound pairs to train the models (default:0.4)\n",
    "    random_seed : int, optional\n",
    "        Seed for random search (default: 10)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    compound_pairs : pd.DataFrame\n",
    "        DataFrame with columns ['prot', 'l1', 'l2', 'Tanimoto', 'y'] containing all N and S pairs.\n",
    "    \"\"\"\n",
    "    random.seed(random_seed)\n",
    "    compound_pairs = pd.DataFrame(columns=['prot', 'l1', 'l2', 'Tanimoto', 'y'])\n",
    "    \n",
    "    for prot in prot_list:\n",
    "        # Select positive ligands (actives) for the current protein\n",
    "        l_pos = base_dataset[(base_dataset['activity'] == 1) & (base_dataset['prot'] == prot)]['lig']\n",
    "        l_pos = cluster_ligands(\n",
    "            l_pos, fps, scaffolds,\n",
    "            bm_clustering=True,\n",
    "            butina_threshold=butina_threshold,\n",
    "            k_means_representatives=k_means_representatives\n",
    "        )\n",
    "        \n",
    "        # Proceed only if there are at least min_positives active ligands\n",
    "        if len(l_pos) > min_positives:\n",
    "            # Select negative ligands (true inactives) for the current protein\n",
    "            l_neg = base_dataset[(base_dataset['activity'] == 0) & (base_dataset['prot'] == prot)]['lig']\n",
    "            l_neg = cluster_ligands(\n",
    "                l_neg, fps, scaffolds,\n",
    "                bm_clustering=True,\n",
    "                butina_threshold=butina_threshold,\n",
    "                k_means_representatives=k_means_representatives\n",
    "            )\n",
    "            \n",
    "            # Add decoys to the set of negatives\n",
    "            decoys_l_neg = get_decoys(l_pos, decoys, scaffolds, n_decoys_per_lig=n_decoys_per_lig)\n",
    "            if len(decoys_l_neg) > len(l_pos):\n",
    "                # If enough decoys, sample proportional to the number of actives\n",
    "                l_neg += random.sample(decoys_l_neg, int(decoys_proportion * len(l_pos)))\n",
    "            else:\n",
    "                # Otherwise, use all available decoys\n",
    "                l_neg += decoys_l_neg\n",
    "\n",
    "            # Generate S pairs: all possible pairs of actives\n",
    "            s_pairs = list(itertools.combinations(l_pos, 2))\n",
    "            tanimoto_s_pairs = compute_tanimoto(s_pairs,fps)\n",
    "            s_pairs_df = pd.DataFrame(s_pairs, columns=['l1', 'l2'])\n",
    "            s_pairs_df['Tanimoto'] = tanimoto_s_pairs\n",
    "            s_pairs_df['y'] = 1  # Mark as similar\n",
    "\n",
    "            # Generate N pairs: all possible pairs of one active and one inactive (or decoy)\n",
    "            n_pairs = list(itertools.product(l_pos, l_neg))\n",
    "            tanimoto_n_pairs = compute_tanimoto(n_pairs,fps)\n",
    "            n_pairs_df = pd.DataFrame(n_pairs, columns=['l1', 'l2'])\n",
    "            n_pairs_df['Tanimoto'] = tanimoto_n_pairs\n",
    "            n_pairs_df['y'] = 0  # Mark as non-similar\n",
    "\n",
    "            # Combine positive and negative pairs\n",
    "            total_pairs_prot = pd.concat([s_pairs_df, n_pairs_df], axis=0)\n",
    "            total_pairs_prot['prot'] = prot\n",
    "\n",
    "            # Filter out pairs with Tanimoto >= the specified threshold\n",
    "            total_pairs_prot = total_pairs_prot[total_pairs_prot['Tanimoto'] < tanimoto_threshold]\n",
    "\n",
    "            # Concatenate with the main DataFrame, keeping relevant columns\n",
    "            compound_pairs = pd.concat([compound_pairs, total_pairs_prot], axis=0)\n",
    "            compound_pairs = compound_pairs[['prot', 'l1', 'l2', 'Tanimoto', 'y']]\n",
    "    \n",
    "    return compound_pairs\n",
    "\n",
    "def shuffle_and_save_chunks(\n",
    "    df, \n",
    "    output_folder, \n",
    "    num_chunks=30, \n",
    "    prefix=\"chunk\", \n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Shuffle the rows of a DataFrame and save it in evenly-sized chunks as CSV files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to shuffle and split.\n",
    "    output_folder : str\n",
    "        Path to the directory where the CSV files will be saved.\n",
    "    num_chunks : int, optional\n",
    "        Number of output chunks/files (default: 30).\n",
    "    prefix : str, optional\n",
    "        Prefix for output file names (default: \"chunk\").\n",
    "    random_state : int, optional\n",
    "        Seed for reproducible shuffling (default: 42).\n",
    "    \"\"\"\n",
    "    # Shuffle the DataFrame rows\n",
    "    df_shuffled = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Compute the approximate size of each chunk\n",
    "    chunk_size = len(df_shuffled) // num_chunks\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Split and save each chunk\n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = len(df_shuffled) if i == num_chunks - 1 else (i + 1) * chunk_size\n",
    "        \n",
    "        # Get the corresponding slice\n",
    "        sub_df = df_shuffled.iloc[start:end]\n",
    "        \n",
    "        # Save as CSV\n",
    "        sub_df.to_csv(\n",
    "            os.path.join(output_folder, f\"{prefix}_{i + 1}.csv\"),\n",
    "            index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20044f1-3334-4e60-838c-4dd1a27ef722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open databases\n",
    "data_dir = 'data'\n",
    "base_dataset = pd.read_csv(f'{data_dir}/prot_ligs_db.csv')\n",
    "# Open fingerprints dictionary\n",
    "with open(f'{data_dir}/comps_fps.pkl','rb') as f:\n",
    "    fps = pickle.load(f) \n",
    "# Open scaffolds dictionary\n",
    "with open(f'{data_dir}/ligs_scaffolds.pkl','rb') as f:\n",
    "    scaffolds = pickle.load(f)\n",
    "# Open decoys dictionary\n",
    "with open(f'{data_dir}/decoys_dict.pkl','rb') as f:\n",
    "    decoys = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26538e4-3442-4816-b991-88ae8c9f833c",
   "metadata": {},
   "source": [
    "## Overview of the databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b28ba1-8a39-422a-9555-679380f1d16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lig</th>\n",
       "      <th>prot</th>\n",
       "      <th>pchembl</th>\n",
       "      <th>comment</th>\n",
       "      <th>pfam</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL514046</td>\n",
       "      <td>P37059</td>\n",
       "      <td>6.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF00106</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL514046</td>\n",
       "      <td>P37059</td>\n",
       "      <td>6.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF00106</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL79955</td>\n",
       "      <td>P11715</td>\n",
       "      <td>4.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF00067</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL78395</td>\n",
       "      <td>P11715</td>\n",
       "      <td>4.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF00067</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL410953</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHEMBL405670</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CHEMBL437250</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>7.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHEMBL428614</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>7.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHEMBL438381</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>7.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHEMBL266048</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHEMBL265871</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>8.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHEMBL385234</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>8.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CHEMBL269275</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>6.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CHEMBL413521</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>8.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHEMBL429520</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>7.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHEMBL387213</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>7.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CHEMBL414288</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>7.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CHEMBL265537</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>8.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CHEMBL385455</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>8.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CHEMBL412790</td>\n",
       "      <td>F5BCZ9</td>\n",
       "      <td>7.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF02364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lig    prot  pchembl comment     pfam  activity\n",
       "0   CHEMBL514046  P37059     6.57     NaN  PF00106       1.0\n",
       "1   CHEMBL514046  P37059     6.60     NaN  PF00106       1.0\n",
       "2    CHEMBL79955  P11715     4.20     NaN  PF00067       0.0\n",
       "3    CHEMBL78395  P11715     4.30     NaN  PF00067       0.0\n",
       "4   CHEMBL410953  F5BCZ9     8.00     NaN  PF02364       1.0\n",
       "5   CHEMBL405670  F5BCZ9     9.00     NaN  PF02364       1.0\n",
       "6   CHEMBL437250  F5BCZ9     7.30     NaN  PF02364       1.0\n",
       "7   CHEMBL428614  F5BCZ9     7.82     NaN  PF02364       1.0\n",
       "8   CHEMBL438381  F5BCZ9     7.52     NaN  PF02364       1.0\n",
       "9   CHEMBL266048  F5BCZ9     8.00     NaN  PF02364       1.0\n",
       "10  CHEMBL265871  F5BCZ9     8.40     NaN  PF02364       1.0\n",
       "11  CHEMBL385234  F5BCZ9     8.22     NaN  PF02364       1.0\n",
       "12  CHEMBL269275  F5BCZ9     6.52     NaN  PF02364       1.0\n",
       "13  CHEMBL413521  F5BCZ9     8.52     NaN  PF02364       1.0\n",
       "14  CHEMBL429520  F5BCZ9     7.60     NaN  PF02364       1.0\n",
       "15  CHEMBL387213  F5BCZ9     7.22     NaN  PF02364       1.0\n",
       "16  CHEMBL414288  F5BCZ9     7.70     NaN  PF02364       1.0\n",
       "17  CHEMBL265537  F5BCZ9     8.52     NaN  PF02364       1.0\n",
       "18  CHEMBL385455  F5BCZ9     8.82     NaN  PF02364       1.0\n",
       "19  CHEMBL412790  F5BCZ9     7.05     NaN  PF02364       1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show base dataset (extracted from ChEMBL)\n",
    "base_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0204b9e0-1831-48e1-ac31-2db0bf3aabd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pfam</th>\n",
       "      <th>Protein Count</th>\n",
       "      <th>Bioactive ligand count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PF00001</td>\n",
       "      <td>487</td>\n",
       "      <td>97166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PF00069</td>\n",
       "      <td>379</td>\n",
       "      <td>41368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PF07714</td>\n",
       "      <td>153</td>\n",
       "      <td>46599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PF00520</td>\n",
       "      <td>95</td>\n",
       "      <td>9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PF00089</td>\n",
       "      <td>81</td>\n",
       "      <td>12013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>PF00266</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>PF00275</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>PF00756</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>PF01702</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>PF00723</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pfam  Protein Count  Bioactive ligand count\n",
       "0    PF00001            487                   97166\n",
       "1    PF00069            379                   41368\n",
       "2    PF07714            153                   46599\n",
       "3    PF00520             95                    9892\n",
       "4    PF00089             81                   12013\n",
       "..       ...            ...                     ...\n",
       "211  PF00266              1                       3\n",
       "212  PF00275              1                       1\n",
       "213  PF00756              1                       1\n",
       "214  PF01702              1                       3\n",
       "215  PF00723              1                       2\n",
       "\n",
       "[216 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show statistics by protein group\n",
    "\n",
    "# Filter only bioactive records (activity == 1.0)\n",
    "bioactive = base_dataset[base_dataset['activity'] == 1.0]\n",
    "\n",
    "# Group by Pfam and calculate the number of unique proteins and unique bioactive ligands\n",
    "stats = bioactive.groupby('pfam').agg(\n",
    "    Protein_Count=('prot', pd.Series.nunique),\n",
    "    Bioactive_ligand_count=('lig', pd.Series.nunique)\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "stats = stats.rename(columns={\n",
    "    'pfam': 'Pfam',\n",
    "    'Protein_Count': 'Protein Count',\n",
    "    'Bioactive_ligand_count': 'Bioactive ligand count'\n",
    "})\n",
    "\n",
    "# Sort by number of unique proteins (descending)\n",
    "stats = stats.sort_values(by='Protein Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the statistics table\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbad6c-15d7-42c4-a6b7-a76ba3471bcd",
   "metadata": {},
   "source": [
    "## Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798dfd8-9608-4c5e-9055-c31823f1f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select proteins for training and test datasets. \n",
    "# As a default example we select the protein group corresponding to Pfam PF00413 (MPG). \n",
    "# We use data from the protein P08254 for testing. Adapt the code to the required protein groups and test proteins.\n",
    "\n",
    "prot_test = ['P08254'] \n",
    "prot_train = [p for p in base_dataset[base_dataset['pfam']== 'PF00413']['prot'].unique() if p not in prot_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e05d57-579c-4894-ad28-c7bd1f0726e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train dataset\n",
    "os.makedirs('./train_datasets', exist_ok=True)\n",
    "\n",
    "train_pairs = generate_compound_pairs(\n",
    "    prot_train, \n",
    "    base_dataset, \n",
    "    fps, \n",
    "    scaffolds, \n",
    "    decoys\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5c2d6-569e-4eac-8d82-eb3100c01a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test dataset\n",
    "os.makedirs('./test_datasets', exist_ok=True)\n",
    "\n",
    "test_pairs = generate_compound_pairs(\n",
    "    prot_test, \n",
    "    base_dataset, \n",
    "    fps, \n",
    "    scaffolds, \n",
    "    decoys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad98a3b-1524-495a-a80f-4514db6a1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training dataset in multiple chunks.\n",
    "# Increasing the number of chunks is recommended for larger datasets to optimize memory usage.\n",
    "\n",
    "num_chunks = 10\n",
    "shuffle_and_save_chunks(train_pairs, './train_datasets/', num_chunks=num_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b096f0-74cf-4953-b61f-ad029ea4e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test dataset if generated\n",
    "test_pairs.to_csv('./test_datasets/test_pairs.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bsi_env]",
   "language": "python",
   "name": "conda-env-bsi_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
