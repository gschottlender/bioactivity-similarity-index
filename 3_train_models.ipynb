{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c80dbc-a5a3-4598-ab45-396bc69e28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from src.model_training_functions import train_model_on_chunks, fine_tune_model_on_chunks, convert_compound_pairs, NeuralNetworkModel\n",
    "from src.model_training_functions import evaluate_test_data, prepare_and_evaluate_pairs\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84a6dd-4cc8-4e49-bb58-e5ab624e3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_auc(test_data, pred_col, binary_sim_col='y'):\n",
    "    \"\"\"\n",
    "    Compute ROC curves and AUC values for the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : pd.DataFrame\n",
    "        DataFrame containing test results, including ground truth and predicted scores.\n",
    "    pred_col : str\n",
    "        Column name for the model's predicted values.\n",
    "    binary_sim_col : str, optional\n",
    "        Column name for the binary similarity label (default: 'y').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    roc_auc_pred : float\n",
    "        Area under the ROC curve for the model's predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute ROC curve and AUC for model predictions\n",
    "    fpr_pred, tpr_pred, _ = roc_curve(test_data[binary_sim_col], test_data[pred_col])\n",
    "    roc_auc_pred = auc(fpr_pred, tpr_pred)\n",
    "\n",
    "    return roc_auc_pred\n",
    "\n",
    "def get_pr_auc(test_data, pred_col, binary_sim_col='y'):\n",
    "    \"\"\"\n",
    "    Compute the area under the Precision-Recall curve (PR AUC) for the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : pd.DataFrame\n",
    "        DataFrame containing test results, including ground truth and predicted scores.\n",
    "    pred_col : str\n",
    "        Column name for the model's predicted values.\n",
    "    binary_sim_col : str, optional\n",
    "        Column name for the binary similarity label (default: 'y').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pr_auc : float\n",
    "        Area under the Precision-Recall curve.\n",
    "    precision : np.ndarray\n",
    "        Precision values for the curve.\n",
    "    recall : np.ndarray\n",
    "        Recall values for the curve.\n",
    "    \"\"\"\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(test_data[binary_sim_col], test_data[pred_col])\n",
    "    # Compute the area under the curve (AUC)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    return pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf26ec-3866-40af-85ba-a81598b8c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fingerprints database\n",
    "data_dir = 'data'\n",
    "\n",
    "# Convert fingerprints to np.float32 format \n",
    "if not 'comps_fps_np.pkl' in os.listdir(data_dir):    \n",
    "    with open(f'{data_dir}/comps_fps.pkl','rb') as f:\n",
    "        db_ligs = pickle.load(f)\n",
    "    \n",
    "    db_ligs = {l:np.array(db_ligs[l], dtype=np.float32) for l in db_ligs}\n",
    "    with open(f'{data_dir}/comps_fps_np.pkl','wb') as f:\n",
    "        pickle.dump(db_ligs,f)\n",
    "else:\n",
    "    with open(f'{data_dir}/comps_fps_np.pkl','rb') as f:\n",
    "        db_ligs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d3cef-d047-43e7-b21d-c7acdc189f34",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75b5ec-86b0-4b91-9a53-01bc367461f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train_datasets'\n",
    "model = train_model_on_chunks(\n",
    "        train_dir,\n",
    "        db_ligs,                # o cualquier recurso que necesites para conv_suma\n",
    "        hidden_layers=[512, 256, 128, 64], \n",
    "        dropout_prob=0.3, \n",
    "        n_epochs=5)\n",
    "\n",
    "torch.save(model.state_dict(), f'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ccff6-86df-426a-bcb1-41451537f83d",
   "metadata": {},
   "source": [
    "## Evaluation on test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c7d38-dbb9-45c6-ad5a-3765f0e0afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_data(model,test_data,db_ligs):\n",
    "    model.eval()\n",
    "    X_test,y_test = convert_compound_pairs(test_data,db_ligs)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    device = next(model.parameters()).device\n",
    "    X_test = X_test.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test).flatten().cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4ca0b-1004-4c04-b85f-0b730ed52d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (same parameters as the trained model)\n",
    "input_size = len(next(iter(db_ligs.values())))\n",
    "model = NeuralNetworkModel(input_size=input_size,hidden_layers=[512,256,128,64],output_size=1,dropout_prob=0.3)\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72975531-118a-474b-8c39-8c8a9e65a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_data = pd.read_csv('./test_datasets/test_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337191b4-02b1-48d4-b0ee-8f40e8f2c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "preds = evaluate_test_data(model,test_data,db_ligs)\n",
    "test_data['pred'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6340b66-f91e-4766-87fb-455bad2a4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC AUC and PR AUC per protein and collect results in a DataFrame\n",
    "\n",
    "results = [\n",
    "    {\n",
    "        \"prot\": prot,\n",
    "        \"ROC AUC\": get_roc_auc(data_prot := test_data[test_data[\"prot\"] == prot], \"pred\"),\n",
    "        \"PR AUC\": get_pr_auc(data_prot, \"pred\")\n",
    "    }\n",
    "    for prot in test_data[\"prot\"].unique()\n",
    "]\n",
    "\n",
    "test_results = pd.DataFrame(results)\n",
    "\n",
    "# Show test results\n",
    "display(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190b6dc-adb2-442f-b69e-fd979b7a59fa",
   "metadata": {},
   "source": [
    "## Example of fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546a9c6-86ee-4a28-8fbc-e83611a3371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "input_size = len(next(iter(db_ligs.values())))\n",
    "model = NeuralNetworkModel(input_size=input_size,hidden_layers=[512,256,128,64],output_size=1,dropout_prob=0.3)\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a88a9-1958-4d01-9165-5b61cf23d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune model (in this example, using the test data)\n",
    "ft_train_dir = './test_datasets/'\n",
    "\n",
    "ft_model = fine_tune_model_on_chunks(\n",
    "    ft_train_dir,\n",
    "    db_ligs,                     # fingerprint dictionary used by convert_compound_pairs\n",
    "    model,               # path to .pt file or an nn.Module instance\n",
    "    n_epochs=5\n",
    ")\n",
    "\n",
    "# To save the model\n",
    "torch.save(ft_model.state_dict(), f'ft_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f5821-4109-496e-8649-24bd0d4e7029",
   "metadata": {},
   "source": [
    "## Evaluation on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b92867-d790-467a-be9d-817644e4b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pairs of compounds (in this example, two lists of SMILES, one for each compound from each pair)\n",
    "compound_list_1 = ['CCCO','O=C(c1ccc(Oc2ccccc2)cc1)N1CCN(c2ncccn2)CC1','CC(C)Nc1ncnc(SC#N)c1[N+](=O)[O-]']\n",
    "compound_list_2 = ['NCCCN(Cc1nn2ccc(Cl)c2c(=O)n1Cc1ccccc1)C(=O)c1ccc(Cl)cc1','CCCCOc1ccccc1C[C@H]1COC(=O)[C@@H]1Cc1ccc(Cl)c(Cl)c1','C=CC(=O)Nc1cccc(Nc2nc(Nc3ccc(SCC(=O)N4CCOCC4)cc3)ncc2Cl)c1']\n",
    "\n",
    "# Generate pair DataFrame\n",
    "new_pairs = pd.DataFrame({'l1':compound_list_1,'l2':compound_list_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b1150b-3ed4-4f17-a4f2-0ea4f9fca266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Pairs with Tanimoto > 0.4 should not be considered,\n",
    "# as the model was exclusively trained on pairs with Tanimoto < 0.4.\n",
    "\n",
    "new_pairs_pred = prepare_and_evaluate_pairs(new_pairs, model)\n",
    "\n",
    "# Show predictions\n",
    "display(new_pairs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff0f31-ed40-4207-b888-9ae4c4a8e687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bsi_env]",
   "language": "python",
   "name": "conda-env-bsi_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
